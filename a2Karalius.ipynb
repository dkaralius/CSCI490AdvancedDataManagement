{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSCI 490 Assignment 2\n",
    "#### Instructor: Dr. David Koop\n",
    "#### Programmer: Dominykas Karalius\n",
    "#### Due at 11:59pm on Friday, February 7\n",
    "#### Z1809478"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloads the .csv file of the hurricane data and creates a dataFrame object from that .csv file, using ',' as a delimiter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "# download the data if we don't have it locally\n",
    "url = \"http://faculty.cs.niu.edu/~dakoop/cs680-2020sp/a2/hurdat2.csv\"\n",
    "local_fname = \"hurdat2.csv\"\n",
    "if not os.path.exists(\"hurdat2.csv\"):\n",
    "    urlretrieve(url, local_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('hurdat2.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.)\n",
    "### Hurricane Names (15 pts)\n",
    "We again wish to compute the number of unique hurricane names and the most frequently used name. First, we must load the data. Pandas has a read_csv method that will load a dataset into a DataFrame object. Recall that we have the hurricane’s name and identifier repeated for each point it was tracked in this dataset. For this part of the analysis, we do not want to have these repeats. Pandas allows us to remove them by (a) projecting the hurricanes to just the identifiers and names and (b) removing duplicates. For (a), you can select a subset of columns using brackets, and multiple columns using a list inside the brackets. For example,\n",
    "\n",
    "  new_df = df[[col1,col2]]\n",
    "creates a new dataframe new_df with only columns col1 and col2. For (b), you can use the drop_duplicates method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.drop_duplicates of       identifier     name\n",
       "0       AL011851  UNNAMED\n",
       "1       AL011851  UNNAMED\n",
       "2       AL011851  UNNAMED\n",
       "3       AL011851  UNNAMED\n",
       "4       AL011851  UNNAMED\n",
       "...          ...      ...\n",
       "51341   AL162018    OSCAR\n",
       "51342   AL162018    OSCAR\n",
       "51343   AL162018    OSCAR\n",
       "51344   AL162018    OSCAR\n",
       "51345   AL162018    OSCAR\n",
       "\n",
       "[51346 rows x 2 columns]>"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = df[['identifier','name']]\n",
    "new_df = new_df.drop_duplicates\n",
    "new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part a\n",
    "### Number of Unique Hurricane Names\n",
    "Using your projected, de-duped data frame, compute the number of unique hurricane names. Remember to remove UNNAMED!\n",
    "\n",
    "Creates a new dataFrame object from the previously generated dataFrame object, however does NOT include hurricanes with the name \"UNNAMED\". We then use the len() method along with the unique() method to find the number of unique hurricane names in the dataFrame object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique hurricane names: 288\n"
     ]
    }
   ],
   "source": [
    "df = df[df['name'] != 'UNNAMED']\n",
    "uniqueName = len(df.name.unique())\n",
    "print(\"Number of unique hurricane names:\",uniqueName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part b\n",
    "### Most frequently used name\n",
    "Using the same data frame, compute the most frequently used name.\n",
    "\n",
    "Creates a variable that will be used to hold name of the most frequent hurricane name. This is done, by using the value_counts() and idxmax() methods together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Frequently Used Name: FLORENCE\n"
     ]
    }
   ],
   "source": [
    "freqName = df['name'].value_counts().idxmax()\n",
    "print(\"Most Frequently Used Name:\",freqName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.)\n",
    "### Year with the Most Hurricanes (10 pts)\n",
    "Now, we need the year with the most hurricanes. Here, we need to have some way to extract the year from the rest of the data. There are (at least) two ways to do this: (a) extract it from the identifier, and (b) extract it from the datetime. For (a), we use pandas string methods on an entire column at once. For example, df.col1.str[:2] extracts the first two characters of col1. For (b), we need to ensure that datetime is understood as a pandas datetime type. This can be accomplished by converting a column using pd.to_datetime method and then using the .dt accessor. For example, pd.to_datetime(col1).dt.month converts a column to datetime and then extracts the month.\n",
    "\n",
    "In both cases, we need to create a new column to store the year. Once you have done this, drop the duplicates to ensure we don’t double-count hurricanes and count the number of occurrences per year.\n",
    "\n",
    "Create a new dataFrame object to be used in problem 2. We then drop_duplicates() so we have no repeating hurricane entries. We then retrieve the datetime entry for each hurricane, but only the first four values, which are the year, using str[:4]. We then use the value_counts() and idxmax() methods together to find the year with the most hurricanes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year with Most Hurricanes: 2005\n"
     ]
    }
   ],
   "source": [
    "df2 = df[['identifier', 'datetime']]\n",
    "df2 = df2.drop_duplicates()\n",
    "print(\"Year with Most Hurricanes:\", df2.datetime.str[:4].value_counts().idxmax())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.)\n",
    "### Minimum latitude and Minimum pressure (15 pts)\n",
    "Now, we will use all of the points that were tracked for the hurricanes to find the hurricane with the maximum latitude and minimum pressure. This time, we don’t need to worry about dropping duplicates. However, if we just use the max and min descriptive statistics, we will only get the values instead of the details about the hurricane name and year. We can either use boolean indexing to find matching values or use the idxmin or idxmax methods to obtain the index of the row that achieves the maximum and then pull out that row.\n",
    "\n",
    "Create a new dataFrame object to be used in problem 3 with identifier, name, num_pts, latitude, min_pressure, and datetime values. Print to check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identifier</th>\n",
       "      <th>name</th>\n",
       "      <th>num_pts</th>\n",
       "      <th>latitude</th>\n",
       "      <th>min_pressure</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>21879</td>\n",
       "      <td>AL011950</td>\n",
       "      <td>ABLE</td>\n",
       "      <td>51</td>\n",
       "      <td>17.1</td>\n",
       "      <td>-999</td>\n",
       "      <td>1950-08-12T00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21880</td>\n",
       "      <td>AL011950</td>\n",
       "      <td>ABLE</td>\n",
       "      <td>51</td>\n",
       "      <td>17.7</td>\n",
       "      <td>-999</td>\n",
       "      <td>1950-08-12T06:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21881</td>\n",
       "      <td>AL011950</td>\n",
       "      <td>ABLE</td>\n",
       "      <td>51</td>\n",
       "      <td>18.2</td>\n",
       "      <td>-999</td>\n",
       "      <td>1950-08-12T12:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21882</td>\n",
       "      <td>AL011950</td>\n",
       "      <td>ABLE</td>\n",
       "      <td>51</td>\n",
       "      <td>19.0</td>\n",
       "      <td>-999</td>\n",
       "      <td>1950-08-12T18:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21883</td>\n",
       "      <td>AL011950</td>\n",
       "      <td>ABLE</td>\n",
       "      <td>51</td>\n",
       "      <td>20.0</td>\n",
       "      <td>-999</td>\n",
       "      <td>1950-08-13T00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51341</td>\n",
       "      <td>AL162018</td>\n",
       "      <td>OSCAR</td>\n",
       "      <td>36</td>\n",
       "      <td>57.9</td>\n",
       "      <td>960</td>\n",
       "      <td>2018-11-03T12:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51342</td>\n",
       "      <td>AL162018</td>\n",
       "      <td>OSCAR</td>\n",
       "      <td>36</td>\n",
       "      <td>58.9</td>\n",
       "      <td>964</td>\n",
       "      <td>2018-11-03T18:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51343</td>\n",
       "      <td>AL162018</td>\n",
       "      <td>OSCAR</td>\n",
       "      <td>36</td>\n",
       "      <td>59.8</td>\n",
       "      <td>968</td>\n",
       "      <td>2018-11-04T00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51344</td>\n",
       "      <td>AL162018</td>\n",
       "      <td>OSCAR</td>\n",
       "      <td>36</td>\n",
       "      <td>60.8</td>\n",
       "      <td>973</td>\n",
       "      <td>2018-11-04T06:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51345</td>\n",
       "      <td>AL162018</td>\n",
       "      <td>OSCAR</td>\n",
       "      <td>36</td>\n",
       "      <td>62.4</td>\n",
       "      <td>977</td>\n",
       "      <td>2018-11-04T12:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24540 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      identifier   name  num_pts  latitude  min_pressure             datetime\n",
       "21879   AL011950   ABLE       51      17.1          -999  1950-08-12T00:00:00\n",
       "21880   AL011950   ABLE       51      17.7          -999  1950-08-12T06:00:00\n",
       "21881   AL011950   ABLE       51      18.2          -999  1950-08-12T12:00:00\n",
       "21882   AL011950   ABLE       51      19.0          -999  1950-08-12T18:00:00\n",
       "21883   AL011950   ABLE       51      20.0          -999  1950-08-13T00:00:00\n",
       "...          ...    ...      ...       ...           ...                  ...\n",
       "51341   AL162018  OSCAR       36      57.9           960  2018-11-03T12:00:00\n",
       "51342   AL162018  OSCAR       36      58.9           964  2018-11-03T18:00:00\n",
       "51343   AL162018  OSCAR       36      59.8           968  2018-11-04T00:00:00\n",
       "51344   AL162018  OSCAR       36      60.8           973  2018-11-04T06:00:00\n",
       "51345   AL162018  OSCAR       36      62.4           977  2018-11-04T12:00:00\n",
       "\n",
       "[24540 rows x 6 columns]"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = df[['identifier', 'name', 'num_pts', 'latitude', 'min_pressure', 'datetime']]\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part a\n",
    "### Farthest South Hurricane Name and Year\n",
    "Find the name, year, and latitude of the hurricane that was tracked farthest south.\n",
    "\n",
    "We find the minimum value of latitude using the idxmin() method and set that value to index. We use index, to pull out the record and find the name, latitude, and year of the hurricane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Southerly Hurricane was ISIDORE in 1990 with a latitude of 7.2 N.\n"
     ]
    }
   ],
   "source": [
    "index = df3.latitude.idxmin()\n",
    "\n",
    "nameMinLat = df3.name.loc[index]\n",
    "minLat = df3.latitude.loc[index]\n",
    "yearMinLat = df3.datetime.str[:4].loc[index]\n",
    "\n",
    "print(\"Most Southerly Hurricane was\", nameMinLat, \"in\", yearMinLat, \"with a latitude of\", minLat, \"N.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part b\n",
    "### b. Hurricane with Minimum Pressure\n",
    "Find the name, year, and pressure of the hurricane that had minimum pressure. Make sure to exclude -999 values!\n",
    "\n",
    "We create a new dataFrame object from our previously generated dataFrame object, but do NOT include -999 values for the minimum pressure. We then find the minimum pressure using the idxmin() method and set that value to index. We use index, to pull out the record and find the name, minimum pressure, and year of the hurricane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hurricane with minimum pressure was WILMA in 2005 with a pressure of 882 millibars.\n"
     ]
    }
   ],
   "source": [
    "df3 = df3[df3['min_pressure'] != -999]\n",
    "index = df3.min_pressure.idxmin()\n",
    "\n",
    "nameMinPressure = df3.name.loc[index]\n",
    "minPressure = df3.min_pressure.loc[index]\n",
    "yearMinPressure = df3.datetime.str[:4].loc[index]\n",
    "\n",
    "print(\"Hurricane with minimum pressure was\", nameMinPressure , \"in\", yearMinPressure, \"with a pressure of\", minPressure, \"millibars.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.)\n",
    "### Year-month Crosstab (15 pts)\n",
    "Pandas features crosstabs so that we can also create a table to analyze the number of hurricanes over years and months. Here, we need the ability to extract both year and month so option (b) from Part 2 is best. Then, the pd.crosstab method allows us to pass in both year and month to obtain the table. Add margins=True to get subtotals for rows and columns.\n",
    "\n",
    "Create a completely new dataFrame object for problem 4 using the same .csv file. We drop the duplicates to prevent repeated entries. We then add two new values to each hurricane, year and month. We get these values by converting the datetime value to datetime and using the .dt accessor method to get the year and month. We then create a final dataFrame object, that only has the year and month values shown. We create a crosstab using our last dataFrame object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>month</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1851</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>49</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1852</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>64</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1853</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>74</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1854</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1855</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>22</td>\n",
       "      <td>15</td>\n",
       "      <td>55</td>\n",
       "      <td>140</td>\n",
       "      <td>59</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2016</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>126</td>\n",
       "      <td>194</td>\n",
       "      <td>103</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>22</td>\n",
       "      <td>126</td>\n",
       "      <td>292</td>\n",
       "      <td>93</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2018</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>102</td>\n",
       "      <td>57</td>\n",
       "      <td>278</td>\n",
       "      <td>130</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>All</td>\n",
       "      <td>174</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>108</td>\n",
       "      <td>701</td>\n",
       "      <td>2461</td>\n",
       "      <td>3440</td>\n",
       "      <td>11224</td>\n",
       "      <td>19831</td>\n",
       "      <td>10203</td>\n",
       "      <td>2683</td>\n",
       "      <td>494</td>\n",
       "      <td>51346</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>169 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "month    1   2   3    4    5     6     7      8      9     10    11   12  \\\n",
       "year                                                                       \n",
       "1851     0   0   0    0    0    14     2     49     16     17     0    0   \n",
       "1852     0   0   0    0    0     0     0     45     64     25     0    0   \n",
       "1853     0   0   0    0    0     0     0     10     74     16     0    0   \n",
       "1854     0   0   0    0    0    11     0      1     36     12     0    0   \n",
       "1855     0   0   0    0    0     0     0     24     11      0     0    0   \n",
       "...    ...  ..  ..  ...  ...   ...   ...    ...    ...    ...   ...  ...   \n",
       "2015     0   0   0    0   28    22    15     55    140     59    20    0   \n",
       "2016    42   0   0    0   20    63     0    126    194    103    38    0   \n",
       "2017     0   0   0   27    0    29    22    126    292     93    21    0   \n",
       "2018     0   0   0    0   26     0   102     57    278    130    15    0   \n",
       "All    174  13  14  108  701  2461  3440  11224  19831  10203  2683  494   \n",
       "\n",
       "month    All  \n",
       "year          \n",
       "1851      98  \n",
       "1852     134  \n",
       "1853     100  \n",
       "1854      60  \n",
       "1855      35  \n",
       "...      ...  \n",
       "2015     339  \n",
       "2016     586  \n",
       "2017     610  \n",
       "2018     608  \n",
       "All    51346  \n",
       "\n",
       "[169 rows x 13 columns]"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4 = pd.read_csv('hurdat2.csv', delimiter=',')\n",
    "df4 = df4.drop_duplicates()\n",
    "df4['year'] = pd.to_datetime(df4['datetime']).dt.year\n",
    "df4['month'] = pd.to_datetime(df4['datetime']).dt.month\n",
    "df5 = df4[['year','month']]\n",
    "\n",
    "pd.crosstab(df5['year'],df5['month'], margins = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.) \n",
    "### [Extra Credit] Incorrect Values (20 pts)\n",
    "The dataset is mostly correct, but there are a couple of interesting errors.\n",
    "\n",
    "Create a new dataFrame object for problem 5. Display only the identifier, name, status, and datetime entries. Drop duplicates to prevent repeated entries. Print to double check if everything works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identifier</th>\n",
       "      <th>name</th>\n",
       "      <th>status</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>AL011851</td>\n",
       "      <td>UNNAMED</td>\n",
       "      <td>HU</td>\n",
       "      <td>1851-06-25T00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>AL011851</td>\n",
       "      <td>UNNAMED</td>\n",
       "      <td>HU</td>\n",
       "      <td>1851-06-25T06:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>AL011851</td>\n",
       "      <td>UNNAMED</td>\n",
       "      <td>HU</td>\n",
       "      <td>1851-06-25T12:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>AL011851</td>\n",
       "      <td>UNNAMED</td>\n",
       "      <td>HU</td>\n",
       "      <td>1851-06-25T18:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>AL011851</td>\n",
       "      <td>UNNAMED</td>\n",
       "      <td>HU</td>\n",
       "      <td>1851-06-25T21:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51341</td>\n",
       "      <td>AL162018</td>\n",
       "      <td>OSCAR</td>\n",
       "      <td>EX</td>\n",
       "      <td>2018-11-03T12:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51342</td>\n",
       "      <td>AL162018</td>\n",
       "      <td>OSCAR</td>\n",
       "      <td>EX</td>\n",
       "      <td>2018-11-03T18:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51343</td>\n",
       "      <td>AL162018</td>\n",
       "      <td>OSCAR</td>\n",
       "      <td>EX</td>\n",
       "      <td>2018-11-04T00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51344</td>\n",
       "      <td>AL162018</td>\n",
       "      <td>OSCAR</td>\n",
       "      <td>EX</td>\n",
       "      <td>2018-11-04T06:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51345</td>\n",
       "      <td>AL162018</td>\n",
       "      <td>OSCAR</td>\n",
       "      <td>EX</td>\n",
       "      <td>2018-11-04T12:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51346 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      identifier     name status             datetime\n",
       "0       AL011851  UNNAMED     HU  1851-06-25T00:00:00\n",
       "1       AL011851  UNNAMED     HU  1851-06-25T06:00:00\n",
       "2       AL011851  UNNAMED     HU  1851-06-25T12:00:00\n",
       "3       AL011851  UNNAMED     HU  1851-06-25T18:00:00\n",
       "4       AL011851  UNNAMED     HU  1851-06-25T21:00:00\n",
       "...          ...      ...    ...                  ...\n",
       "51341   AL162018    OSCAR     EX  2018-11-03T12:00:00\n",
       "51342   AL162018    OSCAR     EX  2018-11-03T18:00:00\n",
       "51343   AL162018    OSCAR     EX  2018-11-04T00:00:00\n",
       "51344   AL162018    OSCAR     EX  2018-11-04T06:00:00\n",
       "51345   AL162018    OSCAR     EX  2018-11-04T12:00:00\n",
       "\n",
       "[51346 rows x 4 columns]"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5 = pd.read_csv('hurdat2.csv', delimiter=',')\n",
    "df5 = df5[['identifier', 'name', 'status', 'datetime']]\n",
    "df5 = df5.drop_duplicates()\n",
    "df5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part a\n",
    "### Incorrect Status (7 pts)\n",
    "There is (at least) one error with one of the entries in the status column. Consult the documentation to see which hurricane status codes are allowed, and find both the anomalous code and the name & year of the hurricane that was incorrectly tagged.\n",
    "\n",
    "Create a list of accepted status codes and check every entry that does NOT have these as a status code. Return the name, code, and year of the hurricane with the incorrect code. Print."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hurricane with incorrect status code was HARVEY in 1993 with a status code of ET .\n"
     ]
    }
   ],
   "source": [
    "acceptedValues = ['TD', 'TS', 'HU', 'EX', 'SD', 'SS', 'LO', 'WV', 'DB']\n",
    "df5 = df5[~df5['status'].isin(acceptedValues)]\n",
    "\n",
    "name = df5.iloc[0]['name']\n",
    "code = df5.iloc[0]['status']\n",
    "year = df5.iloc[0]['datetime']\n",
    "year = year[:4]\n",
    "\n",
    "print(\"Hurricane with incorrect status code was\", name , \"in\", year, \"with a status code of\", code, \".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part b\n",
    "### b. Incorrect Max Wind Flag (13 pts)\n",
    "Check the record_id codes in the documentation. One of those codes flags the time that the hurricane reached its maximum sustained wind speed. However, one of the hurricanes has a reported maximum sustained wind speed (the max_wind column) that is higher than the flagged record. Identify the hurricane as well as that hurricane’s real maximum wind speed.\n",
    "\n",
    "We start off be reading the .csv again to have a clear record. We then print out the entries that have a 'W' value, so that we may record the identifier, which we will use later. We cannot record the names, because there are multiple hurricanes named 'BARRY'.\n",
    "\n",
    "We then create a list of those identifiers and create a for loop. We iterate through every identifier that we previously recorded to have a \"W\" in the record_id value. We record the real max wind speed and the max wind speed that is presented on the \"W\" record_id value. We then compare those values for each identifier. If they are equal, we continue, if not, we print out an error message and the hurricane name, the incorrect max speed, and correct max speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identifier</th>\n",
       "      <th>name</th>\n",
       "      <th>record_id</th>\n",
       "      <th>max_wind</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>38322</td>\n",
       "      <td>AL111991</td>\n",
       "      <td>GRACE</td>\n",
       "      <td>W</td>\n",
       "      <td>90</td>\n",
       "      <td>1991-10-29T14:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39123</td>\n",
       "      <td>AL021995</td>\n",
       "      <td>BARRY</td>\n",
       "      <td>W</td>\n",
       "      <td>60</td>\n",
       "      <td>1995-07-07T21:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43730</td>\n",
       "      <td>AL062004</td>\n",
       "      <td>FRANCES</td>\n",
       "      <td>W</td>\n",
       "      <td>125</td>\n",
       "      <td>2004-09-02T07:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46675</td>\n",
       "      <td>AL112009</td>\n",
       "      <td>IDA</td>\n",
       "      <td>W</td>\n",
       "      <td>75</td>\n",
       "      <td>2009-11-09T21:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      identifier     name record_id  max_wind             datetime\n",
       "38322   AL111991    GRACE         W        90  1991-10-29T14:00:00\n",
       "39123   AL021995    BARRY         W        60  1995-07-07T21:00:00\n",
       "43730   AL062004  FRANCES         W       125  2004-09-02T07:30:00\n",
       "46675   AL112009      IDA         W        75  2009-11-09T21:00:00"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5b = pd.read_csv('hurdat2.csv', delimiter=',')\n",
    "df5b = df5b[['identifier', 'name', 'record_id', 'max_wind','datetime']]\n",
    "df5b = df5b[df5b['record_id'] == 'W']\n",
    "df5b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorrect value found!\n",
      "Hurricane IDA had an incorrect max speed entry of 75 . The real max speed of hurricane IDA is 90 .\n"
     ]
    }
   ],
   "source": [
    "identifierList = []\n",
    "for index, row in df5b.head().iterrows():\n",
    "    identifierList.append(row['identifier']) \n",
    "\n",
    "for i in identifierList:\n",
    "    df6 = pd.read_csv('hurdat2.csv', delimiter=',')\n",
    "    df6 = df6[df6['identifier'] == i ]\n",
    "    realMaxSpeed = df6['max_wind'].max()\n",
    "    df6 = df6[df6['record_id'] == 'W']\n",
    "    maxSpeed = df6['max_wind'].max()\n",
    "    if maxSpeed < realMaxSpeed:\n",
    "        name = df6.iloc[0]['name']\n",
    "        print(\"Incorrect value found!\")\n",
    "        print(\"Hurricane\", name, \"had an incorrect max speed entry of\", maxSpeed, \". The real max speed of hurricane\", name, \"is\", realMaxSpeed, \".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
